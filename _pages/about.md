---
permalink: /
title: "" 
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

Hi there! My name is **Yang Qin (ç§¦é˜³)**. I'm a Ph.D. candidate (since 2021) at [the College of Computer Science](https://cs.scu.edu.cn/e_jsjxy/), [Sichuan University](https://en.scu.edu.cn/), fortunately advised by Prof. [**Dezhong Peng**](https://cs.scu.edu.cn/info/1282/13563.htm) and Prof. [**Peng Hu**](https://penghu-cs.github.io/). I also collaborate closely with Prof. [**Xi Peng**](https://pengxi.me/) and Prof. [**Joey Tianyi Zhou**](https://joeyzhouty.github.io/).

My pursuits center on multimodal learning and large language models, with an emphasis on advancing robustness and cross-modal understanding in AI systems:

- Multimodal Learning ğŸ‘€: Multimodal Fusion & Cross-modal Learning > Investigating multimodal fusion mechanisms and cross-modal representation learning paradigm to enable coherent integration of heterogeneous data sources;
- Robust Machine Learning ğŸ¦¾: [Noisy Correspondence](https://github.com/QinYang79/Noisy-Correspondence-Summary) & Label in Multimodal Learning > Addressing challenges posed by noisy correspondence and labels in multimodal datasets, making efforts towards a unified noise-resilient multimodal learning framework;
- Large Language Models ğŸ¤–: [Code LLMs  & Application of MLLMs/LLMs](https://qinyang-cs.github.io/projects/LLMs) > Exploring open-generation (e.g., code) capabilities and multimodal extensions for real-world applications, including interactive learning and domain-specific knowledge adaptation.

If you are interested in collaborating with me or want to have a chat, please feel free to contact me via email (Any way you like).

# ğŸ”¥ News

- *2025.05.01*, one paper was accepted by ICML 2025 (CCF-A). Congrats to Ruitao and coauthors! ğŸ‰ 
- *2025.04.29*, one paper was accepted by IJCAI 2025 (CCF-A). Congrats to Prof. Hu and coauthors! ğŸ‰ 
- *2025.02.27*, one paper about LLM was accepted by CVPR 2025 (CCF-A). Thanks to all coauthors! ğŸ‰ 
- *2025.01.23*, one paper about LLM was accepted by ICLR 2025 (ğŸ˜€). Thanks to all coauthors! ğŸ‰ 
- *2025.01.19*, one paper was accepted by TMM (JCR Q1). Congrats to Yanglin and coauthors! ğŸ‰
- *2025.01.16*, one paper was accepted by TIFS (CCF-A). Congrats to Yongxiang and coauthors! ğŸ‰
- *2024.12.10*, one paper was accepted by AAAI 2025 (CCF-A). Congrats to Ruitao and coauthors! ğŸ‰
- *2024.10.28*, one paper was accepted by TMM (JCR Q1). Thanks to all coauthors! ğŸ‰
- *2024.07.16*, one paper was accepted by ACM MM 2024 (CCF-A). Congrats to Longan (Undergrad) and coauthors! ğŸ‰
- *2024.06.26*, one paper was accepted by TIP  (CCF-A). Congrats to Yongxiang and coauthors! ğŸ‰
- *2024.06.23*, one paper was accepted by TKDE (CCF-A). Congrats to Yuan and coauthors! ğŸ‰
- *2024.04.20*, one paper was accepted by TMM (JCR Q1). Congrats to Yuan and the coauthors! ğŸ‰
- *2024.02.27*, one paper was accepted by CVPR 2024 (CCF-A). Thanks to all coauthors! ğŸ‰ 
- *2023.09.22*, one paper was accepted by NeurIPS 2023 (CCF-A). Thanks to all coauthors! ğŸ‰ 
- *2022.06.30*, one paper was accepted by ACM MM 2022 (CCF-A). Thanks to all coauthors! ğŸ‰


# ğŸ“ Publications (selected)
- [*CVPR'25*] **Yang Qin**, Chao Chen, Zhihang Fu, Dezhong Peng, Xi Peng, Peng Hu#, [Human-centered Interactive Learning via MLLMs for Text-to-Image Person Re-identification](https://github.com/QinYang79/ICL/blob/main/ICL_paper.pdf), IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2025. [code](https://github.com/QinYang79/ICL)
- [*ICLR'25*] **Yang Qin**, Chao Chen, Zhihang Fu, Ze Chen, Dezhong Peng#, Peng Hu#, Jieping Ye, [ROUTE: Robust Multitask Tuning and Collaboration for Text-to-SQL](https://openreview.net/pdf?id=BAglD6NGy0), International Conference on Learning Representations (ICLR), 2025. [code](https://github.com/alibaba/Route)
- [*TMM'24*] Ruitao Pu*, **Yang Qin\***, Dezhong Peng#, Xiaoming Song, Huiming Zheng, [Deep Reversible Consistency Learning for Cross-modal Retrieval](https://arxiv.org/pdf/2501.05686), IEEE Transactions on Multimedia (TMM), 2024. [code](https://github.com/perquisite/DRCL)
- [*CVPR'24*] **Yang Qin**, Yingke Chen, Dezhong Peng, Xi Peng, Joey Tianyi Zhou, Peng Hu#, [Noisy-Correspondence Learning for Text-to-Image Person Re-identification](https://arxiv.org/pdf/2308.09911.pdf), IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2024.  [code](https://github.com/QinYang79/RDE)
- [*NeurIPS'23*] **Yang Qin**, Yuan Sun, Dezhong Peng, Joey Tianyi Zhou, Xi Peng, Peng Hu#, [Cross-modal Active Complementary Learning with Self-refining Correspondence](https://openreview.net/pdf?id=UBBeUjTja8), Neural Information Processing Systems (NeurIPS), 2023.  [code](https://github.com/QinYang79/CRCL)
- [*ACM MM'22*] **Yang Qin**, Dezhong Peng, Xi Peng, Xu Wang, Peng Hu#, [Deep Evidential Learning with Noisy Correspondence for Cross-modal Retrieval](https://drive.google.com/file/d/1YVXD2ki5txBY6khG62EHwCi6cnQVRE4I/view), Proceedings of the 30th ACM International Conference on Multimedia, 10-14 October 2022. [code](https://github.com/QinYang79/DECL)


- [*ICML'25*] Ruitao Pu, **Yang Qin**, Xiaomin Song, Dezhong Peng, Zhenwen Ren, Yuan Sun, [SHE: Streaming-media Hashing Retrieval](), International Conference on Machine Learning (ICML), 2025. [code]()
- [*TIP'24*] Yongxiang Li, **Yang Qin**, Yuan Sun, Dezhong Peng, Xi Peng, Peng Hu#, [RoMo: Robust Unsupervised Multimodal Learning With Noisy Pseudo Labels](https://ieeexplore.ieee.org/abstract/document/10653726), IEEE Transactions on Image Processing (TIP), 2024. [code](https://github.com/sunyuan-cs/2024-TKDE-RMCNC)
- [*TKDE'24*] Yuan Sun, **Yang Qin**, Yongxiang Li, Dezhong Peng, Xi Peng, Peng Hu#, [Robust Multi-View Clustering With Noisy Correspondence](https://ieeexplore.ieee.org/abstract/document/10595464), IEEE Transactions on Knowledge and Data Engineering (TKDE), 2024. [code](https://github.com/sunyuan-cs/2024-TKDE-RMCNC)


- For the full list of published papers, see [Google Scholar](https://scholar.google.com/citations?user=Ci4FBHoAAAAJ&hl=zh-CN&authuser=1). # and * indicate the corresponding author and equal contribution.

# ğŸ“– Educations and Experiences

- *2021.09 -  now*, PhD, the College of Computer Science, Sichuan University, Chengdu China.
- *2024.05 -  2024.12*, the Research Internship at Alibaba Cloud (Apsara Lab led by [Jieping Ye](https://scholar.google.com/citations?hl=zh-CN&authuser=1&user=T9AzhwcAAAAJ)), Hangzhou China.
- *2017.09 - 2021.06*, Undergraduate,  the College of Software Engineering, Sichuan University, Chengdu China.

# ğŸ– Honors and Awards
- *2024.11*, PhD student National Scholarship.
- *2024.10*, Outstanding Graduate Student of Sichuan University.
- *2023.10*, Tencent Scholarship.
- *2023.10*, Outstanding Graduate Student of Sichuan University.
- *2022.10*, PhD student Innovation Scholarship.

# ğŸ™‹ Services 
- *Conference Reviewer*: NeurIPS, ICLR, ICML, CVPR, ICCV, ECCV, ACMMM, IJCAI, AAAI, AISTATS, etc.
- *Journal Reviewer*: TIP, TNNLS, TVCJ, etc.
