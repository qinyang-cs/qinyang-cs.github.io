---
permalink: /
title: "" 
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

My name is Yang Qin (ç§¦é˜³). I'm a Ph.D. candidate (since 2021) at the College of Computer Science, Sichuan University, fortunately advised by Prof. [Dezhong Peng](https://cs.scu.edu.cn/info/1182/7307.htm) and Prof. [Peng Hu](https://penghu-cs.github.io/). 

My research interests mainly focus on multimodal learning and [noisy correspondence](https://github.com/QinYang79/Noisy-Correspondence-Summary) (NC). Recently, I've been conducting research related to ***LLMs***.

- Multimodal Learning: Multimodal Fusion & Cross-modal Learning
- Noisy Correspondence: NCs in Image-Text Matching and Text-based ReID
- LLMs/MLLMs: [Code LLMs  & Application of MLLMs/LLMs](https://qinyang-cs.github.io/projects/LLMs).
- [**This**](https://docs.google.com/document/d/16XxH3dl3Oq7t8mDBrEaAHKykmLstVLi-MbfouroMYvY/edit?usp=sharing) is a Chinese brief to help MT recruit Research Interns (RI) about LLMs. If you are interested, please get in touch with me.

# ğŸ”¥ News

- *2025.2.27*, one paper about LLM was accepted by CVPR 2025 (CCF-A). Thanks to all coauthors! ğŸ‰ 
- *2025.1.23*, one paper about LLM was accepted by ICLR 2025. Thanks to all coauthors! ğŸ‰ 
- *2025.1.19*, one paper was accepted by TMM (ä¸­ç§‘é™¢1åŒº). Congrats to Yanglin and coauthors! ğŸ‰
- *2025.1.16*, one paper was accepted by TIFS (ä¸­ç§‘é™¢1åŒº, CCF-A). Congrats to Yongxiang and coauthors! ğŸ‰
- *2024.12.10*, one paper was accepted by AAAI 2025 (CCF-A). Congrats to Ruitao and coauthors! ğŸ‰
- *2024.10.28*, one paper was accepted by TMM (ä¸­ç§‘é™¢1åŒº). Thanks to all coauthors! ğŸ‰
- *2024.7.16*, one paper was accepted by ACM MM 2024 (CCF-A). Congrats to Longan (Undergrad) and coauthors! ğŸ‰
- *2024.6.26*, one paper was accepted by TIP  (ä¸­ç§‘é™¢1åŒº, CCF-A). Congrats to Yongxiang and coauthors! ğŸ‰
- *2024.6.23*, one paper was accepted by TKDE (ä¸­ç§‘é™¢1åŒº, CCF-A). Congrats to Yuan and coauthors! ğŸ‰
- *2024.4.20*, one paper was accepted by TMM (ä¸­ç§‘é™¢1åŒº). Congrats to Yuan and the coauthors! ğŸ‰
- *2024.2.27*, one paper was accepted by CVPR 2024 (CCF-A). Thanks to all coauthors! ğŸ‰ 
- *2023.9.22*, one paper was accepted by NeurIPS 2023 (CCF-A). Thanks to all coauthors! ğŸ‰ 
- *2022.6.30*, one paper was accepted by ACM MM 2022 (CCF-A). Thanks to all coauthors! ğŸ‰


# ğŸ“ Publications
- [*CVPR'25*] **Yang Qin**, Chao Chen, Zhihang Fu, Dezhong Peng, Xi Peng, Peng Hu#, [Human-centered Interactive Learning via MLLMs for Text-to-Image Person Re-identification](), IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2025. [code](https://github.com/QinYang79/ICL)
- [*ICLR'25*] **Yang Qin**, Chao Chen, Zhihang Fu, Ze Chen, Dezhong Peng#, Peng Hu#, Jieping Ye, [ROUTE: Robust Multitask Tuning and Collaboration for Text-to-SQL](https://openreview.net/pdf?id=BAglD6NGy0), International Conference on Learning Representations (ICLR), 2025. [code](https://github.com/alibaba/Route)
- [*TMM'24*] Ruitao Pu*, **Yang Qin\***, Dezhong Peng#, Xiaoming Song, Huiming Zheng, [Deep Reversible Consistency Learning for Cross-modal Retrieval](https://arxiv.org/pdf/2501.05686), IEEE Transactions on Multimedia (TMM), 2024. [code](https://github.com/perquisite/DRCL)
- [*CVPR'24*] **Yang Qin**, Yingke Chen, Dezhong Peng, Xi Peng, Joey Tianyi Zhou, Peng Hu#, [Noisy-Correspondence Learning for Text-to-Image Person Re-identification](https://arxiv.org/pdf/2308.09911.pdf), IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2024.  [code](https://github.com/QinYang79/RDE)
- [*NeurIPS'23*] **Yang Qin**, Yuan Sun, Dezhong Peng, Joey Tianyi Zhou, Xi Peng, Peng Hu#, [Cross-modal Active Complementary Learning with Self-refining Correspondence](https://openreview.net/pdf?id=UBBeUjTja8), Neural Information Processing Systems (NeurIPS), 2023.  [code](https://github.com/QinYang79/CRCL)
- [*ACM MM'22*] **Yang Qin**, Dezhong Peng, Xi Peng, Xu Wang, Peng Hu#, [Deep Evidential Learning with Noisy Correspondence for Cross-modal Retrieval](https://drive.google.com/file/d/1YVXD2ki5txBY6khG62EHwCi6cnQVRE4I/view), Proceedings of the 30th ACM International Conference on Multimedia, 10-14 October 2022. [code](https://github.com/QinYang79/DECL)
- For others, see [Google Scholar](https://scholar.google.com/citations?user=Ci4FBHoAAAAJ&hl=zh-CN&authuser=1). # and * indicate the corresponding author and equal contribution.

# ğŸ“– Educations and Experiences

- *2021.09 -  now*, PhD, the College of Computer Science, Sichuan University, Chengdu China.
- *2024.05 -  2024.12*, the Research Internship at Alibaba Cloud (Apsara Lab led by [Jieping Ye](https://scholar.google.com/citations?hl=zh-CN&authuser=1&user=T9AzhwcAAAAJ)), Hangzhou China.
- *2017.09 - 2021.06*, Undergraduate,  the College of Software Engineering, Sichuan University, Chengdu China.

# ğŸ– Honors and Awards
- *2024.11*, PhD student National Scholarship.
- *2024.10*, Outstanding Graduate Student of Sichuan University.
- *2023.10*, Tencent Scholarship.
- *2023.10*, Outstanding Graduate Student of Sichuan University.
- *2022.10*, PhD student Innovation Scholarship.

# ğŸ™‹ Services 
- *Conference Reviewer*: NeurIPS, ICLR, ICML, CVPR, ICCV, ECCV, ACMMM, IJCAI, AAAI, AISTATS, etc.
- *Journal Reviewer*: TIP, TNNLS, TVCJ, etc.
